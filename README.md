# LMArena API Suite

This project contains API testing scripts and an image generation API for lmarena.ai.

## üñºÔ∏è Image Generation API

A Node.js API for generating images using LM Arena's image generation models. Built with Express, Puppeteer-Real-Browser, and a queue system for handling requests.

### Features

- Queue-based request processing
- Optimized image generation with virtual display
- Status tracking for requests
- Health check endpoint
- Docker support

### Quick Start with Docker

1. Build the image:
   ```bash
   docker build -t lmarena .
   ```

2. Run the container:
   ```bash
   docker run -d -p 3000:3000 lmarena
   ```

3. Check if it's running:
   ```bash
   curl http://localhost:3000/health
   ```

### API Endpoints

#### POST /generate
Submit an image generation request.

**Request Body:**
```json
{
  "prompt": "A beautiful sunset over mountains with vibrant colors",
  "model": "ideogram-v3-quality"  // optional, defaults to ideogram-v3-quality
}
```

**Response:**
```json
{
  "requestId": "uuid-string",
  "status": "queued",
  "message": "Request queued for processing",
  "queuePosition": 1
}
```

**Curl Example:**
```bash
curl -X POST http://localhost:3000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "A beautiful sunset over mountains with vibrant colors"}'
```

#### GET /status/:id
Check the status of a request.

**Response:**
```json
{
  "status": "completed",
  "prompt": "A beautiful sunset over mountains with vibrant colors",
  "model": "ideogram-v3-quality",
  "imageUrl": "https://messages-prod.27c852f3500f38c1e7786e2c9ff9e48f.r2.cloudflarestorage.com/...",
  "createdAt": "2025-11-27T06:00:00.000Z",
  "completedAt": "2025-11-27T06:00:45.000Z"
}
```

**Curl Example:**
```bash
curl http://localhost:3000/status/your-request-id-here
```

#### GET /queue
View the current queue status.

**Response:**
```json
{
  "isProcessing": true,
  "queueLength": 2,
  "queue": [
    {
      "id": "uuid-1",
      "prompt": "A beautiful sunset...",
      "model": "ideogram-v3-quality"
    },
    {
      "id": "uuid-2",
      "prompt": "Another prompt...",
      "model": "ideogram-v3-quality"
    }
  ]
}
```

**Curl Example:**
```bash
curl http://localhost:3000/queue
```

#### GET /health
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-27T06:00:00.000Z",
  "queueLength": 0,
  "isProcessing": false
}
```

**Curl Example:**
```bash
curl http://localhost:3000/health
```

### Request Flow

1. **Submit Request:** POST to `/generate` with your prompt
2. **Check Status:** Poll GET `/status/:id` until status is "completed"
3. **Get Image:** Use the `imageUrl` from the completed response

### Status Values

- `queued`: Request is waiting in queue
- `processing`: Request is being processed
- `completed`: Image generation finished successfully
- `failed`: Image generation failed

### Available Models

The API supports the following models available on LM Arena:

- gemini-3-pro-image-preview (nano-banana-pro)
- hunyuan-image-3.0
- gemini-2.5-flash-image-preview-image-generation
- imagen-4.0-ultra-generate-preview-06-06
- imagen-4.0-generate-preview-06-06
- seedream-4-high-res-fal
- wan2.5-t2i-preview
- gpt-image-1
- gpt-image-1-mini
- mai-image-1
- seedream-3
- qwen-image-prompt-extend
- flux-1-kontext-pro
- imagen-3.0-generate-002
- dall-e-3
- flux-1-kontext-dev
- imagen-4.0-fast-generate-001
- flux-2-pro
- flux-2-flex
- hunyuan-image-2.1
- qwen-image-edit
- reve-v1
- reve-fast-edit
- ideogram-v3-quality (default)

### Notes

- Requests are processed sequentially (one at a time)
- Image generation typically takes 30-60 seconds
- URLs are cached for 1 hour
- The API uses a virtual display for browser automation
- Built for LM Arena's image generation interface

### Development

To run locally without Docker:

1. Install dependencies: `npm install`
2. Run the server: `node server.js`

Make sure you have the necessary system dependencies for Puppeteer and Xvfb.

---

## üìÅ API Testing Scripts

This project also contains comprehensive API testing scripts for lmarena.ai endpoints, extracted from HAR file analysis.

## üìÅ Test Scripts Created

### 1. **Stream Evaluation API** (`test_stream_evaluation_api.js`)
- **Endpoint**: `POST /nextjs-api/stream/create-evaluation`
- **Purpose**: Tests the main chat/evaluation streaming API that creates AI model evaluations
- **Status**: ‚ö†Ô∏è Requires authentication (401 error expected)

### 2. **Surveys API** (`test_surveys_api.js`)
- **Endpoint**: `GET /ingest/api/surveys/`
- **Purpose**: Fetches available surveys for user feedback collection
- **Status**: ‚ö†Ô∏è Function export issue (fixed in code)

### 3. **Analytics Ingest API** (`test_analytics_ingest_api.js`)
- **Endpoints**: 
  - `POST /ingest/e/` (Events)
  - `POST /ingest/decide/` (Decisions)
- **Purpose**: Sends analytics and tracking data
- **Status**: ‚ö†Ô∏è Requires proper authentication and data format

### 4. **Chat Pages API** (`test_chat_pages_api.js`) ‚úÖ
- **Endpoints**:
  - `GET /?chat-modality=search`
  - `GET /?chat-modality=image`
  - `GET /leaderboard`
  - `GET /c/new`
- **Purpose**: Tests page navigation and chat initialization
- **Status**: ‚úÖ All working (200 responses)

### 5. **Conversation API** (`test_conversation_post_api.js`) ‚úÖ
- **Endpoints**:
  - `GET /c/{conversation-id}`
  - `POST /c/{conversation-id}`
- **Purpose**: Tests conversation retrieval and message posting
- **Status**: ‚úÖ All working (200 responses)

## üöÄ Usage

### Install Dependencies
```bash
npm install
```

### Run All Tests
```bash
npm test
```

### Run Individual Test Categories
```bash
npm run test:stream      # Stream Evaluation API
npm run test:surveys     # Surveys API
npm run test:analytics   # Analytics Ingest APIs
npm run test:pages       # Chat Pages APIs (‚úÖ Working)
npm run test:conversation # Conversation APIs (‚úÖ Working)
```

## üìä Test Results Summary

**Total Tests**: 10  
**Passed**: 6 ‚úÖ  
**Failed**: 4 ‚ùå  
**Success Rate**: 60%

### ‚úÖ Working APIs
- Search Chat Page (530ms)
- Image Chat Page (538ms) 
- Leaderboard Page (1838ms)
- New Conversation Page (559ms)
- Get Conversation API (935ms)
- Conversation POST API (742ms)

### ‚ùå Failed APIs (Expected)
- Stream Evaluation API (401 - Authentication required)
- Surveys API (Function export issue)
- Events Ingest API (400 - Bad request format)
- Decisions Ingest API (401 - Authentication required)

## üîß Key Features

- **Comprehensive Coverage**: Tests all major API endpoints found in HAR analysis
- **Good Naming**: Each script has descriptive names and clear comments
- **Error Handling**: Proper error catching and reporting
- **Modular Design**: Each API category in separate files
- **Master Runner**: Single command to run all tests
- **Detailed Logging**: Response status, headers, and timing information

## üìù Notes

- Some APIs require authentication tokens that weren't available in the HAR file
- The working APIs demonstrate successful connection to lmarena.ai services
- Failed tests are expected due to authentication and data format requirements
- All scripts include proper headers and user agents from the original requests

## üõ†Ô∏è Next Steps

To make the failing tests work:
1. Obtain proper authentication tokens
2. Update request payloads with correct data formats
3. Add proper session management
4. Implement rate limiting handling